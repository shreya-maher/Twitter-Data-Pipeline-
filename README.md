# Twitter-Data-Pipeline-

![Data_Pipeline - Shreya Maher](https://github.com/shreya-maher/Twitter-Data-Pipeline-/assets/113787713/915c8a21-8db4-4023-bbf6-be940e6cfcc9)

This comprehensive project demonstrates the entire data engineering process, from data extraction to storage, utilizing Airflow and Python. Here's what it encompasses:
  
  **1. Data Sourcing from Twitter API:**
  * Utilize the Twitter API to extract relevant data for analysis.

  **2. Data Transformation with Python:**
  * Employ Python for data transformation tasks, ensuring the extracted data is formatted and prepared for analysis.
  
  **3. Airflow Deployment:**
  * Set up Airflow for workflow management, scheduling, and orchestration of data processing tasks.
  * Deploy the Python code within Airflow to automate the data engineering pipeline.

  **4. Utilization of EC2 for Deployment:**
  * Leverage Amazon EC2 for hosting the Airflow instance, ensuring scalability and reliability of the data processing environment.

  **5. Storage on Amazon S3:**
  * Store the processed data securely and efficiently on Amazon S3, facilitating easy access and scalability.

References: https://www.youtube.com/watch?v=q8q3OFFfY6c&t=743s

